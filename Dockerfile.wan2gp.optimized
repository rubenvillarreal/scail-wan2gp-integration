FROM pytorch/pytorch:2.3.1-cuda12.1-cudnn8-runtime

WORKDIR /app

# ============================================
# Wan2GP-based SCAIL Implementation
# Uses quantized INT8 models (~14GB instead of ~28GB)
# Network volume mounted at /runpod-volume
# ============================================

# ============================================
# LAYER 1: System dependencies
# ============================================
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        ffmpeg libsm6 libxext6 libglib2.0-0 git \
        # Build tools (will be removed after compiling insightface)
        build-essential g++ gcc && \
    rm -rf /var/lib/apt/lists/*

# ============================================
# LAYER 2: Python dependencies
# ============================================
COPY requirements_wan2gp.txt .

# Install PyTorch with support for all GPU architectures
RUN pip install --upgrade pip setuptools wheel && \
    pip install --no-cache-dir --force-reinstall \
        torch==2.3.1 torchvision==0.18.1 \
        --index-url https://download.pytorch.org/whl/cu121 && \
    pip install --no-cache-dir -r requirements_wan2gp.txt && \
    # Remove build tools to reduce image size (~500MB savings)
    apt-get purge -y --auto-remove build-essential g++ gcc && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# ============================================
# LAYER 3: Application code
# ============================================
COPY wan2gp_integration ./wan2gp_integration
COPY runpod_handler_wan2gp.py .

ENV PYTHONPATH=/app \
    HF_HUB_OFFLINE=1 \
    MODEL_BASE_PATH=/runpod-volume \
    PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 \
    CUDA_LAUNCH_BLOCKING=0 \
    TORCH_HOME=/tmp/torch_cache

# RunPod serverless entrypoint
CMD ["python", "-u", "runpod_handler_wan2gp.py"]
