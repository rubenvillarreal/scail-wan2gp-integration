FROM runpod/pytorch:1.0.2-cu1281-torch280-ubuntu2404

WORKDIR /app

# ============================================
# Wan2GP-based SCAIL Implementation
# Uses quantized INT8 models (~14GB instead of ~28GB)
# Network volume mounted at /runpod-volume
# ============================================

# ============================================
# LAYER 1: System dependencies
# ============================================
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        ffmpeg \
        libsm6 \
        libxext6 \
        libglib2.0-0 \
        libgl1 \
        git \
        build-essential \
        g++ \
        gcc \
        cmake \
        ninja-build && \
    rm -rf /var/lib/apt/lists/*

# ============================================
# LAYER 2: Python dependencies
# ============================================
COPY requirements_wan2gp.txt .

# Install requirements (Torch already provided by base image)
RUN pip install --upgrade pip setuptools wheel && \
    pip install --no-cache-dir -r requirements_wan2gp.txt

# Build SageAttention from source (enables sage/sage2 attention modes).
ARG SAGEATTN_REPO=https://github.com/thu-ml/SageAttention.git
ARG TORCH_CUDA_ARCH_LIST=8.9
ARG SAGEATTN_MAX_JOBS=2
ARG SAGEATTN_CMAKE_PARALLEL_LEVEL=2
ARG SAGEATTN_NVCC_THREADS=1
ENV TORCH_CUDA_ARCH_LIST=${TORCH_CUDA_ARCH_LIST}
RUN git clone --depth 1 ${SAGEATTN_REPO} /tmp/SageAttention && \
    MAX_JOBS=${SAGEATTN_MAX_JOBS} \
    CMAKE_BUILD_PARALLEL_LEVEL=${SAGEATTN_CMAKE_PARALLEL_LEVEL} \
    NVCC_THREADS=${SAGEATTN_NVCC_THREADS} \
    pip install --no-cache-dir --no-build-isolation /tmp/SageAttention && \
    rm -rf /tmp/SageAttention

# ============================================
# LAYER 3: Application code
# ============================================
COPY wan2gp_integration ./wan2gp_integration
COPY runpod_handler_wan2gp.py .

ENV PYTHONPATH=/app \
    HF_HUB_OFFLINE=1 \
    MODEL_BASE_PATH=/runpod-volume/models \
    SCAIL_LORA_NAME=/runpod-volume/models/Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors \
    PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 \
    CUDA_LAUNCH_BLOCKING=0 \
    TORCH_HOME=/tmp/torch_cache

# RunPod serverless entrypoint
CMD ["python", "-u", "runpod_handler_wan2gp.py"]
